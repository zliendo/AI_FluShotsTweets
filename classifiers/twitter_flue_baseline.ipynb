{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../labeling_tweets/Data/batch1_to_9.csv', 'rb') as csvfile:\n",
    "    twitter_flu_reader = csv.reader(csvfile)\n",
    "    twitter_flu_list = list(twitter_flu_reader)    \n",
    "random.shuffle(twitter_flu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_flu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets= [row[1] for row in twitter_flu_list]\n",
    "labels = [row[2] for row in twitter_flu_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label values:  ['Y', 'N']\n"
     ]
    }
   ],
   "source": [
    "# label values\n",
    "print 'Label values: ', list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive labels:  454\n"
     ]
    }
   ],
   "source": [
    "print 'Number of positive labels: ' , labels.count(\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_file(data, train_frac = 0.7, dev_frac = 0.15):   \n",
    "    train_split_idx = int(train_frac * len(data))\n",
    "    dev_split_idx = int ((train_frac + dev_frac)* len(data))\n",
    "    train_data = data[:train_split_idx]\n",
    "    dev_data = data[train_split_idx:dev_split_idx]\n",
    "    test_data = data[dev_split_idx:]\n",
    "    return train_data, dev_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set samples: 2800\n",
      "Dev set samples: 600\n",
      "Test set samples: 600\n"
     ]
    }
   ],
   "source": [
    "train_tweets, dev_tweets, test_tweets = split_file (tweets)\n",
    "train_labels, dev_labels, test_labels = split_file (labels)\n",
    "print 'Training set samples:', len (train_tweets)\n",
    "print 'Dev set samples:', len (dev_tweets)\n",
    "print 'Test set samples:', len (test_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_number_features = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TfidfVectorizer\n",
    "# Convert all characters to lowercase before tokenizing (by default)\n",
    "# tokenization (by default)\n",
    "# max_features: consider the top max_features ordered by term frequency across the corpus\n",
    "vectorizer = TfidfVectorizer(max_features=max_number_features,stop_words='english',max_df=0.9 )  \n",
    "train_tweets_vector = vectorizer.fit_transform(train_tweets)\n",
    "dev_tweets_vector = vectorizer.transform(dev_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PerformLogisticRegression(c, train_data, train_labels, dev_data, dev_labels):\n",
    "    model = LogisticRegression(C=c ,class_weight='balanced')\n",
    "    model.fit(train_data, train_labels)   \n",
    "    predicted_labels = model.predict(dev_data)\n",
    "    \n",
    "    #scores\n",
    "    score = metrics.f1_score(dev_labels,predicted_labels, pos_label = \"Y\")\n",
    "    f1a, f1b =metrics.f1_score(dev_labels,predicted_labels, average=None)\n",
    "    precision = metrics.precision_score(dev_labels,predicted_labels, pos_label = \"Y\")\n",
    "    accuracy = np.mean(predicted_labels == dev_labels) \n",
    "    \n",
    "    #roc_auc\n",
    "    predicted_prob = model.predict_proba(dev_data) \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels, predicted_prob[:,1], pos_label = 'Y')\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print ' c: %3.5f ,  accuracy: %3.5f , precision-score:%3.5f,  f1-score: %3.5f, (%3.5f,%3.5f)  roc_auc: %3.5f ' %(c,  accuracy,precision,score , f1a, f1b, roc_auc )\n",
    "    return (score, precision, accuracy,  model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " c: 0.00010 ,  accuracy: 0.61000 , precision-score:0.19286,  f1-score: 0.31579, (0.72727,0.31579)  roc_auc: 0.82281 \n",
      " c: 0.00100 ,  accuracy: 0.75333 , precision-score:0.25287,  f1-score: 0.37288, (0.84647,0.37288)  roc_auc: 0.82303 \n",
      " c: 0.01000 ,  accuracy: 0.84833 , precision-score:0.35644,  f1-score: 0.44172, (0.91225,0.44172)  roc_auc: 0.82342 \n",
      " c: 0.10000 ,  accuracy: 0.83333 , precision-score:0.32727,  f1-score: 0.41860, (0.90272,0.41860)  roc_auc: 0.82768 \n",
      " c: 0.50000 ,  accuracy: 0.84000 , precision-score:0.34545,  f1-score: 0.44186, (0.90661,0.44186)  roc_auc: 0.83229 \n",
      " c: 1.00000 ,  accuracy: 0.84500 , precision-score:0.35780,  f1-score: 0.45614, (0.90962,0.45614)  roc_auc: 0.83094 \n",
      " c: 5.00000 ,  accuracy: 0.84833 , precision-score:0.35354,  f1-score: 0.43478, (0.91242,0.43478)  roc_auc: 0.82126 \n",
      " c: 10.00000 ,  accuracy: 0.84667 , precision-score:0.34375,  f1-score: 0.41772, (0.91171,0.41772)  roc_auc: 0.81137 \n"
     ]
    }
   ],
   "source": [
    " # looking for the best C value \n",
    "c_values =  [ 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0 ]\n",
    "max_score = 0;\n",
    "max_set =()\n",
    "for c in c_values:\n",
    "    score, precision, accuracy, model = PerformLogisticRegression(c, train_tweets_vector, train_labels, dev_tweets_vector, dev_labels)\n",
    "    if (score > max_score):\n",
    "        max_score = score\n",
    "        max_set = (c,accuracy, score, precision, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " best c = 1.00, accuracy = 0.84500, F1-score = 0.45614, precision = 0.35780\n"
     ]
    }
   ],
   "source": [
    "print '\\n best c = %3.2f, accuracy = %2.5f, F1-score = %2.5f, precision = %2.5f' % max_set[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving model for best f1-score \n",
    "LR_model = max_set[4]\n",
    "output = open('twitter_flu_LR_classifier.pkl', 'wb')\n",
    "pickle.dump(LR_model, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving vectorizer\n",
    "output = open('TfidfVectorizer.pkl', 'wb')\n",
    "pickle.dump(vectorizer, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saving dev file just for cross-validation of pkl files\n",
    "#def writeList(setName, filename):\n",
    "#    with  open(filename, 'w') as fout:\n",
    "#        writer = csv.writer(fout, delimiter=',',lineterminator='\\n')\n",
    "#        for row in setName:\n",
    "#            writer.writerow([row])\n",
    "#writeList(dev_tweets,  'dev_tweets.csv')\n",
    "#writeList(dev_labels,  'dev_labels.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
